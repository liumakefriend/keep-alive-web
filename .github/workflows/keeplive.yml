name: Keep Alive Service

on:
  # è®¡åˆ’ä»»åŠ¡è§¦å‘
  schedule:
    # ç­–ç•¥ä¼˜åŒ–ï¼šæ¯ 30 åˆ†é’Ÿè¿è¡Œä¸€æ¬¡ (æ¯å¤© 48 æ¬¡)
    # ç›¸æ¯”åŸæ¥çš„æ¯ 4 å°æ—¶ï¼Œè¿™èƒ½æ›´æœ‰æ•ˆåœ°é˜²æ­¢æœåŠ¡ä¼‘çœ 
    - cron: '*/30 * * * *'
  
  # æ‰‹åŠ¨è§¦å‘
  workflow_dispatch:

jobs:
  visit-websites:
    runs-on: ubuntu-latest
    
    steps:
      - name: Visit URLs
        run: |
          # å®šä¹‰éœ€è¦è®¿é—®çš„ç½‘å€æ•°ç»„
          URLS=(
            "https://huggingface.ber2y.de5.net/"
            "https://koyeb.ber2y.de5.net/"
            "https://koyeb.pitaya.de5.net/"
            "https://clawcloud.pitaya.de5.net/"
          )

          echo "ğŸš€ å¼€å§‹æœ¬æ¬¡ä¿æ´»å·¡æŸ¥..."
          
          # éå†æ¯ä¸ª URL
          for url in "${URLS[@]}"; do
            echo "-----------------------------"
            echo "æ­£åœ¨è®¿é—®: $url"
            
            # ä½¿ç”¨ curl å‘é€è¯·æ±‚
            # --max-time 10: è®¾ç½®è¶…æ—¶æ—¶é—´ä¸º10ç§’ï¼Œé˜²æ­¢å¡æ­»æµªè´¹é¢åº¦
            # --retry 2: å¦‚æœå¤±è´¥è‡ªåŠ¨é‡è¯•2æ¬¡ï¼Œæé«˜æˆåŠŸç‡
            code=$(curl -s -o /dev/null -w "%{http_code}" --max-time 10 --retry 2 --user-agent "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36" "$url")
            
            if [ "$code" == "200" ] || [ "$code" == "301" ] || [ "$code" == "302" ] || [ "$code" == "404" ]; then
              echo "âœ… è®¿é—®æˆåŠŸ (çŠ¶æ€ç : $code)"
            else
              echo "âš ï¸ è®¿é—®å¯èƒ½å¼‚å¸¸ (çŠ¶æ€ç : $code)"
            fi
            
            # è¿™é‡Œçš„ sleep ä»…ä»…æ˜¯ä¸ºäº†ä¸¤ä¸ªè¯·æ±‚é—´ç¨å¾®ç¼“ä¸€ä¸‹ï¼Œä¸å½±å“è®¡è´¹
            sleep 2
          done
          
          echo "-----------------------------"
          echo "ğŸ‰ æœ¬æ¬¡ä»»åŠ¡ç»“æŸï¼Œé‡Šæ”¾èµ„æºã€‚"
          
# on:
#   # è®¡åˆ’ä»»åŠ¡è§¦å‘
#   schedule:
#     # æ¯å¤©åŒ—äº¬æ—¶é—´ 00:00 è¿è¡Œ (ç”±äº GitHub ä½¿ç”¨ UTC æ—¶é—´ï¼Œæ‰€ä»¥è®¾å®šä¸º UTC 16:00)
#     # - cron: '0 16 * * *'
#     - cron: '0 */4 * * *'
#   # æ‰‹åŠ¨è§¦å‘ (æ–¹ä¾¿æµ‹è¯•)
#   workflow_dispatch:

# jobs:
#   visit-websites:
#     runs-on: ubuntu-latest
    
#     steps:
#       - name: Check out code (Optional)
#         uses: actions/checkout@v3

#       - name: Visit URLs 5 times
#         run: |
#           # å®šä¹‰éœ€è¦è®¿é—®çš„ç½‘å€æ•°ç»„
#           URLS=(
#             "https://huggingface.ber2y.de5.net/"
#              "https://koyeb.ber2y.de5.net/"
#              "https://koyeb.pitaya.de5.net/"
#              "https://clawcloud.pitaya.de5.net/"
#              # "https://ebihxdllplbi.ap-northeast-1.clawcloudrun.com/"
#             # "https://itchy-janean-tomato1over-d7f4b8d7.koyeb.app/"
#           )

#           # å¾ªç¯ 5 æ¬¡
#           for ((i=1; i<=5; i++)); do
#             echo "-----------------------------"
#             echo "å¼€å§‹ç¬¬ $i æ¬¡è®¿é—®å¾ªç¯..."
            
#             # éå†æ¯ä¸ª URL
#             for url in "${URLS[@]}"; do
#               echo "æ­£åœ¨è®¿é—®: $url"
#               # ä½¿ç”¨ curl å‘é€è¯·æ±‚
#               # -I: åªè¯·æ±‚å¤´éƒ¨ (å‡å°‘æµé‡)
#               # -s: é™é»˜æ¨¡å¼
#               # -o /dev/null: ä¸è¾“å‡ºå†…å®¹
#               # -w: è¾“å‡º HTTP çŠ¶æ€ç 
#               # --user-agent: ä¼ªè£…æˆæµè§ˆå™¨ï¼Œé˜²æ­¢è¢«æ‹¦æˆª
#               code=$(curl -s -o /dev/null -w "%{http_code}" --user-agent "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36" "$url")
              
#               if [ "$code" == "200" ] || [ "$code" == "301" ] || [ "$code" == "302" ]; then
#                 echo "âœ… è®¿é—®æˆåŠŸ (çŠ¶æ€ç : $code)"
#               else
#                 echo "âš ï¸ è®¿é—®å¯èƒ½å¼‚å¸¸ (çŠ¶æ€ç : $code)"
#               fi
#             done
            
#             # æ¯æ¬¡å¾ªç¯åæš‚åœ 10 ç§’ï¼Œé¿å…è¯·æ±‚è¿‡å¿«è¢«é˜²ç«å¢™æ‹¦æˆª
#             echo "ç­‰å¾… 300 ç§’..."
#             sleep 300
#           done
#           echo "æ‰€æœ‰è®¿é—®ä»»åŠ¡å®Œæˆï¼"
